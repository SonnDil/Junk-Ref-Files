{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe28b0ea",
   "metadata": {},
   "source": [
    "# Vytalogy Financial Results v4_Oct_OCR_pg3\n",
    "\n",
    "#### 1. remove partially duplicated rows using difflib's similarity measure\n",
    "\n",
    "better to check with the extracted csv file and remove partial duplicated rows accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def deduplicated_similar_rows(csv_file, threshold):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    def row_similarity(row1, row2):\n",
    "        return SequenceMatcher(None, str(row1), str(row2)).ratio()\n",
    "    \n",
    "    #list to store indices of rows to be removed\n",
    "    rows_to_remove = []\n",
    "    \n",
    "    #handle bw oth and 1st raw seperately\n",
    "    similarity_0_1 = row_similarity(df.iloc[0], df.iloc[1])\n",
    "    if similarity_0_1 > threshold:\n",
    "        rows_to_remove.append(0)\n",
    "\n",
    "        \n",
    "    for i in range(1,14):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.75:\n",
    "            rows_to_remove.append(i-1)\n",
    "            \n",
    "        \n",
    "    for i in range(15,19):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.9:\n",
    "            rows_to_remove.append(i)\n",
    "            \n",
    "\n",
    "    for i in range(21,36):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.8:\n",
    "            rows_to_remove.append(i-1)\n",
    "            \n",
    "    for i in range(37,40):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.8:\n",
    "            rows_to_remove.append(i)\n",
    "            \n",
    "    for i in range(40,43):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.5:\n",
    "            rows_to_remove.append(i-1)\n",
    "    \n",
    "    for i in range(44,46):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.4:\n",
    "            rows_to_remove.append(i-1)\n",
    "            \n",
    "    for i in range(47,50):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.8:\n",
    "            rows_to_remove.append(i)\n",
    "             \n",
    "    for i in range(50,54):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.8:\n",
    "            rows_to_remove.append(i-1)\n",
    "            \n",
    "    for i in range(54,59):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.8:\n",
    "            rows_to_remove.append(i)      \n",
    "        \n",
    "    for i in range(60,82):\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 0.8:\n",
    "            rows_to_remove.append(i-1)\n",
    "\n",
    "        #replace between letters, digits and % with a period\n",
    "        df.iloc[i] = df.iloc[i].astype(str).replace(r'([a-zA-Z\\d+])\\s+(\\d)%', r'\\1.\\2%', regex = True)\n",
    "        \n",
    "        #replace cells containing \"%\" or \"$\" with NA\n",
    "        df.iloc[i] = df.iloc[i].astype(str).replace(r'^\\$\\s*$', pd.NA, regex =True)\n",
    "        \n",
    "        #replace cells containing \"nan\" with NA\n",
    "        df.iloc[i] = df.iloc[i].astype(str).replace(\"nan\", pd.NA)\n",
    "        \n",
    "    #drop the marked rows and reset the index\n",
    "    df = df.drop(rows_to_remove).reset_index(drop=True)\n",
    "    \n",
    "    #remove rows with high % of nan\n",
    "    nan_rows_to_remove = [i for i in range(1,len(df)) if df.iloc[i].isna().sum() / len(df.columns) > 0.7]\n",
    "    df = df.drop(nan_rows_to_remove).reset_index(drop=True)\n",
    "    \n",
    "    #df = df.iloc[1:]\n",
    "    return df\n",
    "\n",
    "#threshold = 0.75\n",
    "csv_file = \"Vytalogy Financial Results v4_Oct_OCR_pg3.csv\"\n",
    "edited_df = deduplicated_similar_rows(csv_file, threshold)\n",
    "edited_df\n",
    "\n",
    "\n",
    "#edited_df.to_csv(f\"deduplicated_{csv_file}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d87ba",
   "metadata": {},
   "source": [
    "#### 2. taking above duplicated table and now preprocessing all rows using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicated_similar_rows(csv_file, threshold):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    def row_similarity(row1, row2):\n",
    "        return SequenceMatcher(None, str(row1), str(row2)).ratio()\n",
    "    \n",
    "    #list to store indices of rows to be removed\n",
    "    rows_to_remove = []\n",
    "    \n",
    "    #handle bw oth and 1st raw seperately\n",
    "    #similarity_0_1 = row_similarity(df.iloc[1], df.iloc[2])\n",
    "    #if similarity_0_1 > threshold:\n",
    "     #   rows_to_remove.append(2)\n",
    "        \n",
    "    for i in range(1,len(df)):\n",
    "        #if i not in rows_to_remove:\n",
    "        similarity = row_similarity(df.iloc[i-1], df.iloc[i])\n",
    "        if similarity > 1:\n",
    "            rows_to_remove.append(i-1)\n",
    "            \n",
    "    \n",
    "    \n",
    "        #replace between letters, digits and % with a period\n",
    "        df.iloc[i] = df.iloc[i].astype(str).replace(r'([a-zA-Z\\d+])\\s+(\\d)%', r'\\1.\\2%', regex = True)\n",
    "        \n",
    "        #replace cells containing \"%\" or \"$\" with NA\n",
    "        df.iloc[i] = df.iloc[i].astype(str).replace(r'^\\$\\s*$', pd.NA, regex =True)\n",
    "        \n",
    "        #replace cells containing \"nan\" with NA\n",
    "        df.iloc[i] = df.iloc[i].astype(str).replace(\"nan\", pd.NA)\n",
    "        \n",
    "        \n",
    "    #drop the marked rows and reset the index\n",
    "    df = df.drop(rows_to_remove).reset_index(drop=True)\n",
    "    \n",
    "    #remove rows with high % of nan\n",
    "    nan_rows_to_remove = [18]\n",
    "    #nan_rows_to_remove = [i for i in range(1,len(df)) if df.iloc[i].isna().sum() / len(df.columns) > 0.7]\n",
    "    df = df.drop(nan_rows_to_remove).reset_index(drop=True)\n",
    "    \n",
    "    #df = df.drop_duplicates(inplace=True)\n",
    "    #df = df.iloc[1:]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#threshold = 0.2\n",
    "csv_file = \"deduplicated_Vytalogy Financial Results v4_Oct_OCR_pg3.csv\"\n",
    "edited_df = deduplicated_similar_rows(csv_file, threshold)\n",
    "edited_df\n",
    "#edited_df.to_csv(f\"deduplicated_1_new_{csv_file}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
